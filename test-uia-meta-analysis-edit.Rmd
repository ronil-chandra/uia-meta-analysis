---
title: "meta-analysis of proportions"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'uia-meta-analysis-working.html'))})
author: "Ronil V. Chandra"
date: "18/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load required packages

```{r load packages, echo=TRUE, include = TRUE}
library(tidyverse)
library(meta)
library(metafor)

```

# Load required data

```{r load data, echo=TRUE, include = TRUE}

maindata <- read_csv("data/psash-170420-test.csv")

```

# Correct vector types

```{r correct vectors, echo=TRUE}
maindata %>% 
  mutate(pub = as.integer(pub),
         start = as.integer(start),
         end = as.integer(end), 
         psah = as.double(psah),
         fu = as.double(fu),
         nos_select = as.double(nos_select),
         nos_outcome = as.double(nos_outcome),
         nos_compare = as.double(nos_compare),
         nos_outcome = as.double(nos_outcome),
         country = as.factor(country),
         type = as.factor(type))
```

# Confirm new data structure with correct vector types

```{r glimpse new, echo=TRUE}
glimpse(maindata)
view(maindata)
```

# Analyse 10 mm or less aneurysms

```{r select size cohort}

sizedata <- filter(maindata, size == 10) %>%
view()

```


If number of aneurysms is unkown, then assume that 1 patient has 1 aneurysm ie variable num carries forward to num_anr, and is called new vaariable total_size

```{r coalesce patients into aneurysms}

dat <- sizedata %>%
  mutate(total_size = coalesce(num_anr,num)) %>%
  drop_na(total_size) %>%
  select(auth, pub, rupt, total_size)
view(dat)

```

## calculate individual and pooled study proportions 

xi = cases ie number of ruptures during all follow up 
ni = total ie number of aneurysms at study entry
pi = raw proportions ie xi / ni 
yi = individual effect size ie individual proportion in this study
vi = sampling variances

ies = object that holds results of individual effect sizes and corresponding sampling variances

escalc() is a metafor function to estimate individual effect sizes and sampling variances

rma() is a metafor function to fit a random-effects model. This is utilised to take both intra-study and inter-study variances, to increase generalisability. This is because these samples are drawn from different populations, with different comorbidities that may influence outcome, and undergo observation in different conditions. This leads to variation in the outcomes due to random samping error.

pes = object that holds results of pooled effect size and pooled sampling variances. Note that the pooled effect size is the weighted average of the observed effect sizes in the individual studies that are weighted by the inverse of the total variance in that study. 

The distribution of the observed proportions is skewed, and thus we need to transform the data using either the logit or double arcine methods to make it follow a normal distribution and thus enhance the validity of statistical analysis. It will need to be backtransformed later into proportions. 

If the proportion is 0 or 1, the variance is undefined in a logit transformation, and often a continuity correction of 0.5 is applied. 

To better stabilise the variance, and to normalise the distribution especially for small sample sizes, the double arcine method of Freeman-Tukey (Reference Freeman and Tukey 1950) is recommended. This can be later backtransformed using the equation derived by Miller (Reference Miller 1978)

# calculate individual transformed study proportions using DA method


```{r individual DA transformed proportions}
ies.da=escalc(xi=rupt, ni=total_size, data=dat, measure="PFT", add=0)
view(ies.da)

```

# double check if back transform individual transformed values that we should get the original raw proportions

```{r cross check individual back transformation}
transf.ipft(ies.da$yi, ies.da$total_size)
```

# pool the transformed values using a weighted mean according to inverse variance method


```{r pooled DA transformed proportion}

pes.da=rma.uni(yi, vi, data=ies.da, 
               add = 0,
               method = "DL",
               level = 95)
pes.da

```

The DA method proposed by Freeman-Tukey transforms the data, stabilises the sampling variance, and allows us to carry out statistical analysis. Using the transformed data, we can then fit our chosen statistical models.  

rma.uni fits a linear (random/fixed or mixed) model without moderaters. Here, we have chosen a DerSimonian and Laird model (DL) method, and the summary proportion is calculated by weighting the studies using the inverse variance method. Note that the condfidence intervals are calculated using the Wald method ie assuming a normal distribution. 

Note that if the proportion is 0, then a constant may be added. Ensure that there is no adjustment to observed proportions by specifying add=0. 

The DL method is also used to estimate between-study variance using the statistic tau-squared, and can be estimated using different random-effects models. 

# back transformation is required to obtain the summary proportion. 

```{r pooled proportion}

pes <- predict(pes.da, transf=transf.ipft.hm, targs=list(ni=dat$total_size))
pes

```

Simply using the harmonic mean of the sample sizes as suggested by Miller et al 1978 and applying this to all the individual studies creates misleading results for each individual study.

Instead, the back transformation to the pooled proportion needs to be carried out using study-specific sample sizes. 

# create a new tibble for individual study back transformation

```{r individual back transformation}

dat.back <- summary(ies.da, transf = transf.ipft, ni = dat$total_size)
view(dat.back)

```


# display the individual and pooled proportions as a forest plot

```{r simple forest after back transformation}

forest(dat.back$yi, ci.lb=dat.back$ci.lb, ci.ub=dat.back$ci.ub, 
       psize=1,
       xlim=c(-0.5,1.8), alim=c(0,1), ylim=c(-1,8), refline=NA, digits=3L,
       xlab="Proportion", header=c("Study", "Proportion [95% CI]"))
addpoly(pes$pred, ci.lb=pes$ci.lb, ci.ub=pes$ci.ub, row=-0.5, digits=3,
        mlab="RE Model", efac=1.3) 
abline(h=0.5)

```


#Utilise metaprop function from meta

Metaprop can be used to caclulate an overall proportion from studies reporting a single proportion. Pooling methods are the inverse variance and generalised linear mixed models (GLMM).

Our options are to pool untransformed proportions or pool transformed proportions according to logit or DA methods. 

The choice of meta-analytic method for transformed proportions is controversial. Some authors suggest utilisation of the DA method and inverse variance for study weighting, while others suggest utilisation of GLMMs with logit transformation. 

However, given the extreme skewedness of the initial data, the rarity of the outcome event ie p=0 is common, the logits will become undefined. The addition of a continuity correction of 0.5, which is commonly employed can bias the results further. Thus the DA method with inverse variance study weighing will be performed initially prior to GLMM.

# Meta-analysis of proportions using inverse variance DL method and Normal approximimation method for CIs

```{r meta-analysis of proportions with DL and NAsm method for CIs}

pes.summary.nasm = metaprop(rupt, total_size, data=dat, 
                     sm = "PFT", 
                     method.tau = "DL",
                     method.ci = "NAsm",
                     pscale = 1) 
pes.summary.nasm



```

Note that this is the same result as performing the individual steps using the metafor package. 


# Meta-analysis of proportions using inverse variance DL method and CP method for CIs

```{r meta-analysis of proportions with DL and CP method for CIs}

pes.summary.cp = metaprop(rupt, total_size, 
                          data=dat, 
                          sm = "PFT", 
                          method.tau = "DL",
                          method.ci = "CP",
                          pscale = 1) 
pes.summary.cp

```

# Meta-analysis of proportions using inverse variance DL method and Wilson score interval method for CIs


```{r meta-analysis of proportions with DL and Wilson method for CIs}

pes.summary.wilson = metaprop(rupt, total_size,
                              data=dat, 
                              sm = "PFT", 
                              method.tau = "DL",
                              method.ci = "WS",
                              pscale = 1) 
pes.summary.wilson

```


The choice of CI is important given the rarity of the outcome event ie p=0 is common which creates a highly skewed distribution. 

The Wilson method is chosen for 2 main reasons, as recommended by Vollset 1993, Agresti 1998, and Newcombe 1998 and Brown 2001. 

Firstly, as compared to the exact Clopper-Pearson method, the Wilson method is more accurate when the sample size is small, can be applied to all sample sizes, and derives an interval that more accurately reflects the true interval in the population of interest. 

For this situation of aneurysm rupture in small unruptured aneurysms, p is very close to 0, and thus the Clopper-Pearson exact method can result in overcoverage since n is small, and even when n is large, the derived CI does not accurately reflect the true population CI when p is very close to 0. 

Note the differences in the CIs between the CP and Wilson method, particulary on the lower boundary. Given the statistical considerations in choosing the Wilson method, overcoverage using the CP method is confirmed. 


# A simple forest plot with inverse variance DL and Wilson method for CIs

```{r simple forest with DL and Wilson method for CIs, fig.width = 10}

forest(pes.summary.wilson,
       xlim=c(0,10),
       pscale = 100,
       digits = 4)

```

# Using generalised linear mixed methods models (GLMMs).

Single proportions that have binomial structure are generally transformed using logit, arcine or DA methods. These are then backtransformed to the original scale. 

While all back transformations are possible, the methodology of Miller 1978 is typically utilised using the harmonic mean of the sample sizes. However, for highly skewed distribution of sample sizes, the harmonic mean is affected, and this can affect the backtransformed proportions. 

This anomaly has been confirmed by Schwarzer 2019 and use of a GLMM (random intercept logistic regression model) is recommended. Although there are shortcomings of the logit transformation with classic random-effects meta-analysis methods as highlighted above (issues with p=0 and continuity corrections), they do not apply to the GLMM.

This is because the classic meta-analysis methods assume that the effect follows a normal distribution, while the GLMM takes into account the binomial structure of the data as noted by Stinjen 2010. 


```{r meta-analysis of proportions using glmm}

pes.summary.glmm = metaprop(rupt, total_size,
                            data=dat,
                            sm="PLOGIT",
                            method.tau = "ML", 
                            method.ci = "WS",
                            pscale = 100) 
pes.summary.glmm

```

Note that the GLMM ie a random intercept logistic regression model is the default method for the logit transformation. Also the the maximum-likelihood method is utilized for GLMMs.


# Display GLMM result using a simple forest plot


```{r simple forst using glmm}

forest(pes.summary.glmm,
       xlim=c(0,10),
       digits = 4)

```

Note the diffences in the GLMM model compared to classic meta-analytic methods. This produces the least biased results and reasonable coverage probabilities for the 95% CI, as suggested by Stinjen 2010.

Note CIs are using Wilson score method


# Publication quality forest plots

# Still working on everything below this line



```{r forest for publication using GLMM, fig.width = 10}


forest(pes.summary.glmm,
       layout = "JAMA",
       xlim=c(0,10),
       xlab = "Percent Rupture Risk") 

```



















## Assess and quantify heterogeniety - both between-study variance and within-study variance

This is required to assess whether the pooled proportion provides an accurate summary of the finding of interest. If there is high heterogeneity then interpretation of the data synthesis should be taken with caution. 

Heterogeniety arises from both between-study and within-study variance. 

Between-study variance arises from differences in the baseline populations, participant characteristics, study designs and study environment. Intra-study variance arises from random sampling error.

The between-study variance is calculated as the statistic tau-squared, and can be estimated using different random-effects models. 

Although the DerSimonian and Laird (DL) method is most popular, this under-estimates between-study variance, and produces overly narrow CIs when between-study variance is high. DL estimates of tau-squared are particularly inaccurate when number of included studies is small. The HKSJ method consistently results in more adequate error rates and better performance when the number of studies is small, and when there are unequal sample sizes. 


```{r individual proportions with DA transformation using SJ method}

ies.da.sj=escalc(xi=rupt, ni=total_size, data=dat, measure="PFT", add=0) 
pes.da.sj=rma(yi, vi, data=ies.da.sj, method = "SJ", level = 95)
pes2=predict(pes.da.sj, transf=transf.ipft.hm, targ=list(ni=dat$total_size)) 
print(pes2, digits = 6)

```


This is important because the estimated amount of the between-study variance influences the weights assigned to each study and hence the overall summary effect size and the precision of the effect size. 


# Calculate Higgins I2 to quantify heterogeneity (model = SJ).

This is important because if there is moderate to substantial heterogeneity, then the summary effect is of little value. 

```{r heterogeniety SJ calculation}

print(pes.da.sj, digits = 4) 
confint(pes.da.sj, digits = 2)
```

# Understand the output of the random-effect model  

Random-Effects Model (k = 3; tau^2 estimator: SJ)

This line tells us that a random effects model was used, k = 3 means that 3 studies were included and that the estimation used was the SJ method ie Sidik-Jonkman 

tau^2 (estimated amount of total heterogeneity): 0.0003 (SE = 0.0006)

This line tells us the value of tau squared which estimates the total amount of study heterogeniety. When Tau-squared is zero this is indicative of no heterogeneity.

I^2 (total heterogeneity / total variability):   20.83%

This line tells us the value of I squared. I^2 represents the proportion of observed variation that can be attributed to the actual between-study variance. I^2 thresholds within 25, 50, and 75% represent low, moderate, and high variance, respectively.

Q(df = 2) = 1.2594, p-val = 0.5327

This line shows the Q-statistic with degrees of freedom. This also assesses the ratio of observed variation that can be attributed to actual between-study variance. However the advantages of I^2 are that unlike the Q statistic, the I^2 is not sensitive to the number of studies includeed, and that CIs can also be calculated for I^2. Thus it is suggested to utilise I^2. If the p value for the Q statistic is below 0.05, then this suggests that there is significant between-study heterogeneity. 


Model results 
estimate      se    zval    pval   ci.lb   ci.ub 
  0.1037  0.0225  4.6174  <.0001  0.0597  0.1478  *** 
  
This shows the results of the random-effects model, and the estimate of the effect size with the standard error, z statistics, p values, and 95% CIs. 

In our case of meta-analysis of proportions, this is not correct, as the result of the random effects meta-analysis has not been back tranformed into the summary proportion. 

# Baujat plots to visually assess which studies contribute most to heterogeniety

```{r baujat plots}

b_plot <- rma(yi, vi, data = ies.da, method = "SJ", level = 95)
baujat(b_plot)

```

We can use these sources of heterogeniety to assess for moderating variables that may contribute to the heterogeneity 

## Next carry out formal tests to identify outliers and influential studies

Screen studies by checking their externally studentized residuals (z-value) . Studentized residuals are more effective for detecting outliers than standardized residuals. If an observation has an externally studentized residual that is larger than 2 it may be an outlier, if it is larger than 3, it is an outlier. 

```{r externally studentized residuals}

stud.res=rstudent(pes.da.sj) 
abs.z=abs(stud.res$z) 
stud.res[order(-abs.z)]

```

Once we have screened studies, include all potential outliers with z-values of 2 or more for leave-one-out analysis

```{r table of leave-one-out testing}

l1o = leave1out(pes.da.sj, transf=transf.ipft.hm, targ=list(ni=dat$total_10))
print(l1o, digits = 4)

```

The summary estimate at line 1 is the summary proportion when the first study is removed, and the summary proportion recalculated. 

This can be displayed as a forest plot as well for visual analysis. 

yi = individual effect size ie individual proportion in this study
vi = sampling variances

```{r forest of leave-out-testing}

l1o=leave1out(pes.da.sj)
yi=l1o$estimate; vi=l1o$se^2
forest(yi, vi, transf=transf.ipft.hm,
       targ=list(ni=dat$total_size), 
       slab=paste(dat$authpub), 
       refline=pes$pred,
       xlab="Summary proportions leaving out each study",
       digits = 4)

```

Verify this information with likely influential studies, using metafor testing. 

```{r influence testing}

inf=influence(pes.da.sj)
print(inf)
plot(inf)
```

In this 3 study sample, no influential studies have been identified. 


# Identify outliers and consider whether these outlier studies are influential. 

This helps identify potential moderating variables to account for between study heterogeneity. 

Perform a leave-one-out analysis by removing each study in turn, and then re-estimating the summary proportion based on n-1 studies. 

## Start by ordering studies by precision and assessing visually 

```{r assess precision and re-do simple forest plot}

precision=sqrt(ies.da.sj$vi) 
pes.summary=metaprop(rupt, total_size, data=dat, sm="PFT", method.tau = "SJ", method.ci = "WS") 
forest(pes.summary,
       pscale = 100,
       sortvar = precision,
       xlim=c(0,10),
       digits = 4)

```

This shows that the point estimate and confidence intervals are lower when the studies are larger. This might indicate publication bias, or instead a true difference in the effect size because of differences in the underlying populations included. 


# create a funnel plot

```{r funnel plot}

funnel(pes.da.sj, xlab = "Double arcine transformed rupture risk")

```


# Test for bias - Eggers and Rank Correlation

## Eggers test

```{r eggers}

regtest(pes.da.sj)

```

Eggers regression test is not sigificant, so there is no evidence of publication bias. 

## Rank Correlation test

```{r rank correlation}
ranktest(pes.da.sj)
```

Rank correlation test is not significant, so there is no evidence of publication bias. 

# Perform moderator analysis

## Moderator analysis for study type

```{r moderator study type}

pes.modtype=rma(yi, vi, mods = ~ type, data=ies.da.sj, method = "SJ", level = 95)
pes.modtype

```

As the p value is greater than 0.05, this means that study type did not moderate the pooled proportion. 

## Moderator analysis for country

```{r moderator country}

pes.modcountry=rma(yi, vi, mods = ~ country, data=ies.da.sj, method = "SJ", level = 95)
pes.modcountry

```

## Sub-group proportions

Firstly, we should assume that between-study variance may differ across the sub-groups. Thus we need to apply a mixed-effects model. First apply a random effects models to each subgroup, to allow the between-study variances to be different, and then fit a fixed effect model to combine studies within each sub-group to produce the summary effect size estimate. 

Note that at least 5 studies each are required for each moderator in a multivariate meta-regression model. Thus to begin moderator analysis, you'll need at least 10 studies. In our example, given the total of 15 studies in the 3 mm or less cohort, and 31 studies total, only 2 moderators were chosen which are aneurysm size at study entry and previous exposure to subarachnoid haemorrhage. 



